

## Solution

1. `torch.nn.functional.relu` -> `mxnet.ndarray.relu`
2. `torch.nn.functional.sigmoid` -> `mxnet.ndarray.sigmoid`
3. `torch.nn.functional.tanh` -> `mxnet.ndarray.tanh`
4. `torch.nn.functional.softmax` -> `mxnet.ndarray.softmax`
5. `torch.nn.functional.log_softmax` -> `mxnet.ndarray.log_softmax`
6. `torch.nn.functional.elu` -> `mxnet.ndarray.elu`
7. `torch.nn.functional.leaky_relu` -> `mxnet.ndarray.LeakyReLU`
8. `torch.nn.functional.prelu` -> `mxnet.ndarray.prelu`
9. `torch.nn.functional.celu` -> `mxnet.ndarray.celu`
10. `torch.nn.functional.gelu` -> `mxnet.ndarray.gelu`